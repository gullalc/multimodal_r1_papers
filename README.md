# Deepseek RL (GRPO)-Inspired Research for Vision & Multimodal Reasoning

This repository maintains a curated and updated collection of research papers and repositories focused on Reinforcement Learning (RL)-inspired methods such as Group Relative Policy Optimization (GRPO) applied to Vision and Multimodal Reasoning tasks.

## Papers

| Date           | Paper                                                                                                                                               | Repository                                                |
|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------|
| Apr 10, 2025  |  [VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning](https://arxiv.org/abs/2504.07956)                            |  [Github](https://github.com/zhishuifeiqian/VCR-Bench)  |
| Apr 9, 2025 | [VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning](https://arxiv.org/abs/2504.06958)                                   |  [Github](https://github.com/OpenGVLab/VideoChat-R1)  |
| Apr 8, 2025  | [Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought](https://arxiv.org/abs/2504.05599)                                                |  [Github](https://github.com/SkyworkAI/Skywork-R1V)  |
| Apr 3, 2025  | [Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme](https://arxiv.org/abs/2504.02587)  | [Github](https://github.com/GAIR-NLP/MAYE)  |
| Apr 1, 2025  | [Improved Visual-Spatial Reasoning via R1-Zero-Like Training](https://arxiv.org/abs/2504.00883)  | [Github](https://github.com/zhijie-group/R1-Zero-VSI) |
| Apr 1, 2025  | [Think or Not Think: A Study of Explicit Thinking inRule-Based Visual Reinforcement Fine-Tuning](https://arxiv.org/abs/2503.16188)  | [Github](https://github.com/minglllli/CLS-RL)  |
| Mar 31, 2025  | [Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1](https://arxiv.org/abs/2503.24376)  | [Github](https://github.com/TencentARC/SEED-Bench-R1)  |
| Mar 28, 2025   | [OThink-MR1: Stimulating multimodal generalized reasoning capabilities via dynamic reinforcement learning](https://arxiv.org/abs/2503.16081)  | - |
| Mar 27, 2025  | [Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning](https://arxiv.org/abs/2503.20752)  | [Github](https://github.com/tanhuajie/Reason-RFT)  |
| Mar 27, 2025   | [Video-R1: Reinforcing Video Reasoning in MLLMs](https://arxiv.org/abs/2503.21776)                                                                   | [Github](https://github.com/tulerfeng/Video-R1)          |
| Mar 23, 2025   | [Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning](https://arxiv.org/abs/2503.18013) | [Github](https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1) |
| Mar 21, 2025   | [OpenVLThinker: An Early Exploration to Complex Vision-Language Reasoning via Iterative Self-Improvement](https://arxiv.org/abs/2503.17352) | [Github](https://github.com/yihedeng9/OpenVLThinker) | 
| Mar 18, 2025   | [Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning](https://arxiv.org/abs/2503.15558)                                                | [Github](https://github.com/nvidia-cosmos/cosmos-reason1)  |
| Mar 18, 2025   | [DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding](https://arxiv.org/abs/2503.12797) | [Github](https://github.com/thunlp/DeepPerception)        |
| Mar 17, 2025   | [R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization](https://arxiv.org/abs/2503.12937) | [GitHub](https://github.com/jingyi0000/R1-VL)             |
| Mar 13, 2025   | [R1-Onevision: Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization](https://arxiv.org/abs/2503.10615)                       | [GitHub](https://github.com/Fancy-MLLM/R1-onevision)      |
| Mar 10, 2025   | [LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL](https://arxiv.org/abs/2503.07536)                       | [GitHub](https://github.com/TideDra/lmm-r1)               |
| Mar 10, 2025   | [MM-Eureka: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning](https://arxiv.org/abs/2503.07365)                        | [GitHub](https://github.com/ModalMinds/MM-EUREKA)         |
| Mar 10, 2025   | [Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning](https://arxiv.org/abs/2503.07065)       | [GitHub](https://github.com/ding523/Curr_REFT)            |
| Mar 9, 2025    | [Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models](https://arxiv.org/abs/2503.06749)                                | [GitHub](https://github.com/Osilly/Vision-R1)             |
| Mar 7, 2025    | [R1-Zero's "Aha Moment" in Visual Reasoning on a 2B Non-SFT Model](https://arxiv.org/abs/2503.05132)                                                 | [GitHub](https://github.com/turningpoint-ai/VisualThinker-R1-Zero) |
| Mar 4, 2025    | [Visual-RFT: Visual Reinforcement Fine-Tuning](https://huggingface.co/papers/2503.01785)                                                             | [GitHub](https://github.com/Liuziyu77/Visual-RFT)         |
| Feb 27, 2025   | [MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning](https://arxiv.org/abs/2502.19634) | - |
| Feb 27, 2025   | [Med-RLVR: Emerging Medical Reasoning from a 3B base model via Reinforcement Learning](https://arxiv.org/abs/2502.19655)                             | - |
| Feb 20, 2025   | [AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO](https://arxiv.org/abs/2502.14669)                                        | [GitHub](https://github.com/menloresearch/visual-thinker) |

## Repositories Only
- [VLM-R1: A stable and generalizable R1-style Large Vision-Language Model](https://github.com/om-ai-lab/VLM-R1)
- [R1-V: Reinforcing Super Generalization Ability in Vision Language Models with Less Than $3](https://github.com/Deep-Agent/R1-V)
- [Multimodal Open R1](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal)


## Surveys
- [Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)](https://arxiv.org/abs/2504.03151)
- [A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond](https://arxiv.org/abs/2503.21614) | [Github](https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning)
- [Aligning Multimodal LLM with Human Preference: A Survey](https://arxiv.org/abs/2503.14504) | [Github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Alignment)
